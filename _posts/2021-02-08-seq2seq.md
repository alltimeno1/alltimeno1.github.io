---
title: Sequence-to-Sequence
tags: 머신러닝/딥러닝
---

**인코더 & 디코더**

<img src="https://user-images.githubusercontent.com/71831714/107194775-d8e9a800-6a33-11eb-9638-6862171f6cb2.png" width="50%" height="50%">

<br>

인코더는 데이터의 특징을 추출하고 디코더는 압축된 데이터를 복원하는 역할



**Sequence-to-Sequence**

챗봇과 번역 등 자연어 문제를 학습하기 위해 널리 사용되고 있는 RNN 구조

<img src="https://user-images.githubusercontent.com/71831714/107194778-da1ad500-6a33-11eb-85f4-009cfe16815a.png" width="70%" height="70%">

<br>

seq2seq은 인코더와 디코더로 구성되어 있다.

<br>

인코더는 모든 단어들을 순차적으로 입력받은 뒤에 정보들을 압축하여 context vector를 만든 후 디코더로 전송한다.

디코더는 context vector와 최초 입력값 \<SOS>를 통해 다음에 나올 단어를 예측하고 그 단어는 다음 RNN의 입력값이 된다.

<br>
